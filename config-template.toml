# StochasticProcess-RAG 配置文件

[api]
# API 提供商配置
provider = ""
base_url = ""
api_key = ""

[model]
# 模型配置 - 按优先级尝试，第一个失败就用下一个
chat_models = ["claude-sonnet-4-5-20250929", "claude-opus-4-5-20251101-thinking"]
embedding_model = "local"  # 使用本地 HuggingFace embedding 模型
temperature = 0.3

# ===== 离线模式配置 =====
offline_mode = false  # 设为 true 启用离线模式（完全不联网）
local_llm_url = "http://localhost:11434"  # Ollama 服务地址
# 推荐模型（按显存需求从小到大）：
#   - qwen2.5:1.5b  (~1GB, 适合 2-4GB 显存)
#   - qwen2.5:3b    (~2GB, 适合 4-6GB 显存)
#   - phi3:mini     (~2.5GB, 适合 4-6GB 显存)
#   - qwen2.5:7b    (~5GB, 需要 6GB+ 显存)
local_llm_model = "qwen2.5:3b"  # 推荐 4GB 显存使用 3b 模型

[database]
# 向量数据库配置
chroma_dir = "./chroma_db"
solutions_dir = "./solutions"

[ingestion]
# 文档处理配置
pdf_path = "data/SP-10-12.pdf"
chunk_size = 800
chunk_overlap = 150
max_problems_to_solve = 0  # 0 表示解答所有题目，否则只解答前 N 个

[retrieval]
# 检索配置
top_k = 5  # 每次检索返回的文档数量

[topics]
# 需要生成补充知识的核心主题
core_topics = [
    "马尔可夫链的定义和转移概率矩阵",
    "泊松过程及其无记忆性",
    "常返态与瞬时态的定义和判定",
    "随机过程的样本空间、事件类和概率测度",
    "更新过程与到达过程",
    "随机游走及其性质",
]
