"""
æ–‡æ¡£æ‘„å…¥ä¸å‘é‡åŒ–æ¨¡å—
åŠŸèƒ½ï¼šè§£æ PDF æ–‡æ¡£ã€æå–ä¾‹é¢˜ä¹ é¢˜ã€è°ƒç”¨ API è§£ç­”ã€å‘é‡åŒ–å¹¶å­˜å‚¨åˆ° Chroma æ•°æ®åº“
"""

import os
import re
import json
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.documents import Document
from config_manager import (
    get_api_config, get_model_config, get_database_config,
    get_ingestion_config, get_topics
)


def get_embeddings():
    """è·å– Embedding æ¨¡å‹ï¼ˆä½¿ç”¨ OpenAI å…¼å®¹æ¥å£ï¼‰"""
    api_config = get_api_config()
    model_config = get_model_config()
    
    return OpenAIEmbeddings(
        model=model_config.get("embedding_model", "text-embedding-3-small"),
        openai_api_key=api_config["api_key"],
        openai_api_base=api_config["base_url"],
    )


def get_llm():
    """è·å– LLM å®ä¾‹"""
    api_config = get_api_config()
    model_config = get_model_config()
    
    return ChatOpenAI(
        model=model_config.get("chat_model", "gemini-3-pro-preview"),
        temperature=model_config.get("temperature", 0.3),
        openai_api_key=api_config["api_key"],
        openai_api_base=api_config["base_url"],
    )


def load_and_split_pdf(pdf_path, chunk_size=800, chunk_overlap=150):
    """åŠ è½½ PDF å¹¶åˆ‡åˆ†æ–‡æ¡£"""
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ PDF: {pdf_path}")
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} é¡µ")
    
    separators = [
        "\nã€ä¾‹é¢˜",
        "\nã€ä¾‹",
        "\nä¾‹é¢˜",
        "\nä¹ é¢˜",
        "\nÂ§",
        "\nå®šä¹‰",
        "\nå®šç†",
        "\nè¯æ˜",
        "\n\n",
        "\n",
        "ã€‚",
        " ",
        ""
    ]
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=separators,
        length_function=len,
    )
    
    print(f"ğŸ”ª æ­£åœ¨åˆ‡åˆ†æ–‡æ¡£ (chunk_size={chunk_size}, overlap={chunk_overlap})...")
    splits = text_splitter.split_documents(documents)
    print(f"âœ… æˆåŠŸåˆ‡åˆ†ä¸º {len(splits)} ä¸ªç‰‡æ®µ")
    
    return splits, documents


def extract_problems(documents):
    """ä»æ–‡æ¡£ä¸­æå–ä¾‹é¢˜å’Œä¹ é¢˜ï¼ˆè¯¾åä½œä¸šï¼‰"""
    problems = []
    
    # åˆå¹¶æ‰€æœ‰é¡µé¢å†…å®¹
    full_text = "\n".join([doc.page_content for doc in documents])
    
    # ä¾‹é¢˜åŒ¹é…æ¨¡å¼ - æ›´å…¨é¢
    example_patterns = [
        # ã€ä¾‹é¢˜ X.Yã€‘æ ¼å¼
        (r'ã€ä¾‹é¢˜\s*([\d\.]+)ã€‘\s*(.+?)(?=ã€ä¾‹é¢˜|ã€ä¾‹|ä¾‹é¢˜\s*[\d\.]|ä¾‹\s*[\d\.]|Â§|$)', 'example'),
        # ã€ä¾‹ X.Yã€‘æ ¼å¼  
        (r'ã€ä¾‹\s*([\d\.]+)ã€‘\s*(.+?)(?=ã€ä¾‹é¢˜|ã€ä¾‹|ä¾‹é¢˜\s*[\d\.]|ä¾‹\s*[\d\.]|Â§|$)', 'example'),
        # ä¾‹é¢˜ X.Y æ ¼å¼ï¼ˆæ— æ–¹æ‹¬å·ï¼Œæœ‰ç©ºæ ¼ï¼‰
        (r'(?<![ã€])ä¾‹é¢˜\s+([\d\.]+)\s*(.+?)(?=ä¾‹é¢˜\s*[\d\.]|ä¾‹\s*[\d\.]|Â§|$)', 'example'),
        # ä¾‹é¢˜X.Y æ ¼å¼ï¼ˆæ— ç©ºæ ¼ï¼‰
        (r'(?<![ã€])ä¾‹é¢˜([\d\.]+)\s*(.+?)(?=ä¾‹é¢˜[\d\.]|ä¾‹\s*[\d\.]|Â§|$)', 'example'),
        # ä¾‹ X.Y.Z æ ¼å¼ï¼ˆå¦‚ ä¾‹0.1.1ï¼‰
        (r'(?<![ã€ä¾‹é¢˜])ä¾‹\s*([\d\.]+)\s*(.+?)(?=ä¾‹é¢˜|ä¾‹\s*[\d\.]|Â§|$)', 'example'),
    ]
    
    seen_ids = set()
    
    # æå–ä¾‹é¢˜
    for pattern, prob_type in example_patterns:
        try:
            matches = re.findall(pattern, full_text, re.DOTALL)
            for match in matches:
                prob_id = match[0].strip()
                content = match[1].strip()
                
                # æ ‡å‡†åŒ– IDï¼ˆå»é™¤å¤šä½™ç©ºæ ¼ï¼‰
                prob_id = re.sub(r'\s+', '', prob_id)
                
                unique_key = f"example_{prob_id}"
                if unique_key in seen_ids:
                    continue
                seen_ids.add(unique_key)
                
                if len(content) > 30:
                    content = re.sub(r'\s+', ' ', content)[:2000]
                    problems.append({
                        'id': f"ä¾‹é¢˜{prob_id}",
                        'content': content,
                        'type': 'example'
                    })
        except Exception as e:
            print(f"  âš ï¸ æ¨¡å¼åŒ¹é…é”™è¯¯: {str(e)}")
    
    # æå–è¯¾åä½œä¸š
    homework_sections = re.findall(r'Â§\s*([\d\.]+)\s*è¯¾åä½œä¸š\s*\n(.+?)(?=Â§|\Z)', full_text, re.DOTALL)
    for section_id, section_content in homework_sections:
        # åœ¨æ¯ä¸ªä½œä¸šç« èŠ‚ä¸­æå–å•ç‹¬çš„é¢˜ç›®
        hw_problems = re.findall(r'(\d+)\.\s*(.+?)(?=\n\d+\.|$)', section_content, re.DOTALL)
        for hw_num, hw_content in hw_problems:
            prob_id = f"{section_id}.{hw_num}"
            unique_key = f"hw_{prob_id}"
            
            if unique_key in seen_ids:
                continue
            seen_ids.add(unique_key)
            
            hw_content = hw_content.strip()
            if len(hw_content) > 20:
                hw_content = re.sub(r'\s+', ' ', hw_content)[:2000]
                problems.append({
                    'id': f"ä¹ é¢˜{prob_id}",
                    'content': hw_content,
                    'type': 'exercise'
                })
    
    # æŒ‰ç±»å‹å’Œ ID æ’åº
    def sort_key(p):
        # æå–æ•°å­—è¿›è¡Œæ’åº
        nums = re.findall(r'[\d\.]+', p['id'])
        if nums:
            parts = nums[0].split('.')
            return (0 if p['type'] == 'example' else 1, 
                    [float(x) if x else 0 for x in parts])
        return (2, [999])
    
    problems.sort(key=sort_key)
    
    return problems


def solve_problem_with_api(llm, problem_id, problem_content, problem_type):
    """ä½¿ç”¨ API è§£ç­”ä¾‹é¢˜æˆ–ä¹ é¢˜ï¼Œæ­£ç¡®å¤„ç†æ•°å­¦å…¬å¼"""
    type_name = 'ä¾‹é¢˜' if problem_type == 'example' else 'ä¹ é¢˜'
    
    prompt = f"""ä½ æ˜¯ä¸€ä½æ¦‚ç‡è®ºä¸éšæœºè¿‡ç¨‹é¢†åŸŸçš„èµ„æ·±æ•°å­¦æ•™æˆã€‚è¯·è¯¦ç»†è§£ç­”ä»¥ä¸‹{type_name}ï¼Œå¹¶ä¸”ä¸è¦æœ‰å®¢å¥—è¯ï¼Œç›´æ¥å®Œæˆè¦æ±‚å³å¯ã€‚

**é‡è¦è¯´æ˜**ï¼šé¢˜ç›®ä¸­å¯èƒ½åŒ…å«æ•°å­¦å…¬å¼ï¼Œè¯·ä»”ç»†è¯†åˆ«å¹¶æ­£ç¡®ç†è§£ã€‚

---
## {type_name} {problem_id}

{problem_content}

---

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼ä¸¥æ ¼å›ç­”ï¼š

### é¢˜ç›®åˆ†æ
- ç®€æ´æ˜äº†ï¼Œä¸ç”¨åˆ†ç‚¹
- è¯†åˆ«é¢˜ç›®ä¸­çš„æ•°å­¦ç¬¦å·å’Œå…¬å¼
- åˆ†ææœ¬é¢˜è€ƒæŸ¥çš„æ ¸å¿ƒæ¦‚å¿µï¼ˆå¦‚é©¬å°”å¯å¤«é“¾ã€æ³Šæ¾è¿‡ç¨‹ã€éšæœºæ¸¸èµ°ç­‰ï¼‰
- æ˜ç¡®éœ€è¦æ±‚è§£çš„ç›®æ ‡

### è§£é¢˜è¿‡ç¨‹
ç»™å‡ºå®Œæ•´è¯¦ç»†çš„è§£é¢˜æ­¥éª¤ã€‚**æ‰€æœ‰æ•°å­¦å…¬å¼å¿…é¡»ä½¿ç”¨ LaTeX æ ¼å¼**ï¼š
- è¡Œå†…å…¬å¼ä½¿ç”¨ `$...$`ï¼Œä¾‹å¦‚ï¼š$P(X=k)$
- è¡Œé—´å…¬å¼ä½¿ç”¨ `$$...$$`ï¼Œä¾‹å¦‚ï¼š
$$P_{{ij}} = P(X_{{n+1}}=j | X_n=i)$$

è¯·ç¡®ä¿ï¼š
1. æ¯ä¸€æ­¥æ¨å¯¼éƒ½æœ‰æ¸…æ™°çš„è§£é‡Š
2. å…¬å¼ä¹¦å†™è§„èŒƒï¼Œä½¿ç”¨æ­£ç¡®çš„ LaTeX è¯­æ³•
3. æ¦‚ç‡ç¬¦å·ã€æœŸæœ›ã€æ–¹å·®ç­‰ä½¿ç”¨æ ‡å‡†è®°å·

### ç­”æ¡ˆ
ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œç”¨æ•°å­¦å…¬å¼è¡¨è¾¾

### çŸ¥è¯†å»¶ä¼¸
- ç®€æ´æ˜äº†
- æ€»ç»“æœ¬é¢˜æ¶‰åŠçš„å®šç†å’Œæ€§è´¨
- åˆ—å‡ºç›¸å…³çš„é‡è¦å…¬å¼
- æŒ‡å‡ºå¸¸è§çš„è§£é¢˜æŠ€å·§å’Œæ˜“é”™ç‚¹

è¯·å¼€å§‹è§£ç­”ï¼š"""
    
    try:
        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        print(f"  âš ï¸ API è°ƒç”¨å¤±è´¥: {str(e)}")
        return None


def generate_supplementary_knowledge(llm, topic):
    """ä½¿ç”¨ API ç”Ÿæˆè¡¥å……çŸ¥è¯†ï¼Œæ­£ç¡®è¾“å‡ºæ•°å­¦å…¬å¼"""
    prompt = f"""ä½ æ˜¯ä¸€ä½æ¦‚ç‡è®ºä¸éšæœºè¿‡ç¨‹é¢†åŸŸçš„ä¸“å®¶æ•™æˆã€‚è¯·é’ˆå¯¹ä»¥ä¸‹ä¸»é¢˜æä¾›ç³»ç»Ÿã€è¯¦ç»†çš„çŸ¥è¯†è®²è§£ã€‚

**ä¸»é¢˜**ï¼š{topic}

**æ ¼å¼è¦æ±‚**ï¼š
- æ‰€æœ‰æ•°å­¦å…¬å¼å¿…é¡»ä½¿ç”¨ LaTeX æ ¼å¼
- è¡Œå†…å…¬å¼ä½¿ç”¨ `$...$`
- è¡Œé—´å…¬å¼ä½¿ç”¨ `$$...$$`
- ä½¿ç”¨æ ‡å‡†çš„æ¦‚ç‡è®ºè®°å·ï¼ˆå¦‚ $P$, $E$, $\operatorname{{Var}}$, $\sigma$ ç­‰ï¼‰

---

è¯·åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

## 1. åŸºæœ¬å®šä¹‰
ç»™å‡ºä¸¥æ ¼çš„æ•°å­¦å®šä¹‰ã€‚ä¾‹å¦‚ï¼š
$$P(A|B) = \\frac{{P(A \\cap B)}}{{P(B)}}$$

## 2. æ ¸å¿ƒæ€§è´¨
åˆ—ä¸¾é‡è¦çš„æ€§è´¨å’Œå®šç†ï¼Œæ¯ä¸ªæ€§è´¨ç”¨å…¬å¼è¡¨è¾¾

## 3. å…³é”®å…¬å¼
ç»™å‡ºå¸¸ç”¨çš„è®¡ç®—å…¬å¼ï¼Œå¦‚æ¦‚ç‡è®¡ç®—ã€æœŸæœ›ã€æ–¹å·®ç­‰
ç”¨å…¬å¼åˆ—è¡¨å½¢å¼å±•ç¤º

## 4. å…¸å‹ä¾‹å­
ç”¨å…·ä½“æ•°å€¼ä¸¾ä¾‹è¯´æ˜æ¦‚å¿µçš„åº”ç”¨
åŒ…å«å®Œæ•´çš„è®¡ç®—è¿‡ç¨‹

## 5. ä¸å…¶ä»–æ¦‚å¿µçš„è”ç³»
è¯´æ˜ä¸ç›¸å…³æ¦‚å¿µï¼ˆé©¬å°”å¯å¤«é“¾ã€æ³Šæ¾è¿‡ç¨‹ã€éšæœºæ¸¸èµ°ç­‰ï¼‰çš„å…³ç³»

## 6. å¸¸è§è€ƒç‚¹ä¸æ˜“é”™ç‚¹
- å­¦ä¹ è¦ç‚¹
- å¸¸è§é”™è¯¯
- è§£é¢˜æŠ€å·§

è¯·ä½¿ç”¨ä¸¥è°¨çš„æ•°å­¦è¯­è¨€è¿›è¡Œé˜è¿°ï¼š"""
    
    try:
        response = llm.invoke(prompt)
        return response.content
    except Exception as e:
        print(f"  âš ï¸ çŸ¥è¯†ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None


def create_vectorstore(documents, persist_directory):
    """åˆ›å»ºå‘é‡å­˜å‚¨"""
    print(f"ğŸ§  æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹...")
    embeddings = get_embeddings()
    
    print(f"ğŸ’¾ æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“å¹¶æŒä¹…åŒ–åˆ°: {persist_directory}")
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        persist_directory=persist_directory
    )
    
    print(f"âœ… å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸï¼")
    return vectorstore


def main():
    """ä¸»å‡½æ•°"""
    # ä»é…ç½®è¯»å–å‚æ•°
    db_config = get_database_config()
    ing_config = get_ingestion_config()
    
    PDF_PATH = ing_config.get("pdf_path", "data/SP-10-12.pdf")
    CHROMA_DIR = db_config.get("chroma_dir", "./chroma_db")
    SOLUTIONS_DIR = db_config.get("solutions_dir", "./solutions")
    CHUNK_SIZE = ing_config.get("chunk_size", 800)
    CHUNK_OVERLAP = ing_config.get("chunk_overlap", 150)
    MAX_PROBLEMS = ing_config.get("max_problems_to_solve", 10)
    
    # æ£€æŸ¥ PDF æ˜¯å¦å­˜åœ¨
    if not os.path.exists(PDF_PATH):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° PDF æ–‡ä»¶ {PDF_PATH}")
        return
    
    # å¦‚æœå‘é‡æ•°æ®åº“å·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦é‡å»º
    if os.path.exists(CHROMA_DIR):
        response = input(f"âš ï¸  å‘é‡æ•°æ®åº“ {CHROMA_DIR} å·²å­˜åœ¨ï¼Œæ˜¯å¦é‡å»ºï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            print("âŒ å–æ¶ˆæ“ä½œ")
            return
        print("ğŸ—‘ï¸  åˆ é™¤æ—§æ•°æ®åº“...")
        import shutil
        shutil.rmtree(CHROMA_DIR)
    
    # åˆ›å»ºç›®å½•
    Path(SOLUTIONS_DIR).mkdir(exist_ok=True)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½å’Œåˆ‡åˆ†æ–‡æ¡£
        splits, raw_documents = load_and_split_pdf(PDF_PATH, CHUNK_SIZE, CHUNK_OVERLAP)
        
        # æ‰“å°ç¤ºä¾‹ç‰‡æ®µ
        print("\nğŸ“„ ç¤ºä¾‹æ–‡æ¡£ç‰‡æ®µ:")
        print("-" * 60)
        print(splits[0].page_content[:300])
        print("-" * 60)
        
        # æ­¥éª¤ 2: æå–ä¾‹é¢˜å’Œä¹ é¢˜
        print("\nğŸ” æ­£åœ¨æå–ä¾‹é¢˜å’Œä¹ é¢˜...")
        problems = extract_problems(raw_documents)
        print(f"âœ… æ‰¾åˆ° {len(problems)} ä¸ªä¾‹é¢˜/ä¹ é¢˜")
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„é¢˜ç›®åˆ—è¡¨
        examples = [p for p in problems if p['type'] == 'example']
        exercises = [p for p in problems if p['type'] == 'exercise']
        print(f"\nğŸ“‹ é¢˜ç›®ç»Ÿè®¡: {len(examples)} ä¸ªä¾‹é¢˜, {len(exercises)} ä¸ªä¹ é¢˜")
        
        # ç”Ÿæˆé¢˜ç›®ç´¢å¼•æ–‡æ¡£
        index_file = f"{SOLUTIONS_DIR}/é¢˜ç›®ç´¢å¼•.md"
        print(f"\nğŸ“ æ­£åœ¨ç”Ÿæˆé¢˜ç›®ç´¢å¼•æ–‡æ¡£: {index_file}")
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write("# éšæœºè¿‡ç¨‹ - é¢˜ç›®ç´¢å¼•\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {Path(PDF_PATH).stem}\n\n")
            f.write(f"**æ€»è®¡**: {len(problems)} é“é¢˜ç›® ({len(examples)} ä¾‹é¢˜ + {len(exercises)} ä¹ é¢˜)\n\n")
            f.write("---\n\n")
            
            # å†™å…¥ä¾‹é¢˜
            if examples:
                f.write("## ä¾‹é¢˜åˆ—è¡¨\n\n")
                for i, p in enumerate(examples, 1):
                    f.write(f"### {p['id']}\n\n")
                    f.write(f"{p['content']}\n\n")
                    f.write("---\n\n")
            
            # å†™å…¥ä¹ é¢˜
            if exercises:
                f.write("## ä¹ é¢˜åˆ—è¡¨ï¼ˆè¯¾åä½œä¸šï¼‰\n\n")
                for i, p in enumerate(exercises, 1):
                    f.write(f"### {p['id']}\n\n")
                    f.write(f"{p['content']}\n\n")
                    f.write("---\n\n")
        
        print(f"âœ… é¢˜ç›®ç´¢å¼•å·²ä¿å­˜åˆ°: {index_file}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†é¢˜ç›®é¢„è§ˆ
        print("\nğŸ“‹ é¢˜ç›®é¢„è§ˆ (å‰20ä¸ª):")
        for i, p in enumerate(problems[:20], 1):
            print(f"  {i}. {p['id']}: {p['content'][:40]}...")
        if len(problems) > 20:
            print(f"  ... è¿˜æœ‰ {len(problems) - 20} ä¸ªé¢˜ç›® (å®Œæ•´åˆ—è¡¨è§ {index_file})")
        
        # æ­¥éª¤ 3: æŒ‰ç« èŠ‚ç»„ç»‡é¢˜ç›®å¹¶ä½¿ç”¨ API è§£ç­”
        llm = get_llm()
        solved_docs = []
        
        # æŒ‰ç« èŠ‚åˆ†ç»„é¢˜ç›®
        def get_chapter(prob_id):
            """ä»é¢˜ç›®IDæå–ç« èŠ‚å·"""
            nums = re.findall(r'[\d]+', prob_id)
            if nums:
                return nums[0]  # ç¬¬ä¸€ä¸ªæ•°å­—ä½œä¸ºç« èŠ‚å·
            return "å…¶ä»–"
        
        # åˆ†ç»„
        chapters = {}
        for prob in problems:
            chapter = get_chapter(prob['id'])
            if chapter not in chapters:
                chapters[chapter] = []
            chapters[chapter].append(prob)
        
        print(f"\nğŸ“š æŒ‰ç« èŠ‚åˆ†ç»„:")
        for ch, probs in sorted(chapters.items(), key=lambda x: int(x[0]) if x[0].isdigit() else 999):
            print(f"  ç¬¬ {ch} ç« : {len(probs)} é“é¢˜ç›®")
        
        # è§£ç­”æ‰€æœ‰é¢˜ç›®å¹¶æŒ‰ç« èŠ‚ç”Ÿæˆæ–‡æ¡£
        problems_to_solve = problems if MAX_PROBLEMS == 0 else problems[:MAX_PROBLEMS]
        
        if problems_to_solve:
            print(f"\nğŸ“ æ­£åœ¨ä½¿ç”¨ API è§£ç­” {len(problems_to_solve)} ä¸ªé¢˜ç›®...")
            
            # ç”¨äºæ”¶é›†æ¯ç« çš„è§£ç­”
            chapter_solutions = {}
            
            for i, prob in enumerate(problems_to_solve, 1):
                chapter = get_chapter(prob['id'])
                print(f"  [{i}/{len(problems_to_solve)}] æ­£åœ¨è§£ç­” {prob['id']}...")
                
                solution = solve_problem_with_api(llm, prob['id'], prob['content'], prob['type'])
                
                if solution:
                    # æ”¶é›†åˆ°å¯¹åº”ç« èŠ‚
                    if chapter not in chapter_solutions:
                        chapter_solutions[chapter] = []
                    chapter_solutions[chapter].append({
                        'id': prob['id'],
                        'content': prob['content'],
                        'solution': solution,
                        'type': prob['type']
                    })
                    
                    # æ·»åŠ åˆ°å‘é‡åº“
                    solved_docs.append(Document(
                        page_content=f"{prob['id']}ï¼š{prob['content']}\n\nè§£ç­”ï¼š{solution}",
                        metadata={
                            'type': 'solved_problem', 
                            'problem_id': prob['id'],
                            'problem_type': prob['type'],
                            'chapter': chapter
                        }
                    ))
                    print(f"    âœ… å·²è§£ç­”")
            
            # æŒ‰ç« èŠ‚ç”Ÿæˆæ–‡æ¡£
            print(f"\nğŸ“„ æ­£åœ¨ç”Ÿæˆç« èŠ‚è§£ç­”æ–‡æ¡£...")
            for chapter, solutions in sorted(chapter_solutions.items(), key=lambda x: int(x[0]) if x[0].isdigit() else 999):
                chapter_file = f"{SOLUTIONS_DIR}/ç¬¬{chapter}ç« _é¢˜ç›®ä¸è§£ç­”.md"
                with open(chapter_file, 'w', encoding='utf-8') as f:
                    f.write(f"# ç¬¬ {chapter} ç«  - é¢˜ç›®ä¸è§£ç­”\n\n")
                    f.write(f"**æœ¬ç« å…± {len(solutions)} é“é¢˜ç›®**\n\n")
                    f.write("---\n\n")
                    
                    for sol in solutions:
                        type_label = "ä¾‹é¢˜" if sol['type'] == 'example' else "ä¹ é¢˜"
                        f.write(f"## {sol['id']}\n\n")
                        f.write(f"### é¢˜ç›®\n\n{sol['content']}\n\n")
                        f.write(f"### è§£ç­”\n\n{sol['solution']}\n\n")
                        f.write("---\n\n")
                
                print(f"  âœ… å·²ç”Ÿæˆ: {chapter_file} ({len(solutions)} é“é¢˜)")
        
        # ç”Ÿæˆè¡¥å……çŸ¥è¯†
        core_topics = get_topics()
        if core_topics:
            print(f"\nğŸ“š æ­£åœ¨ç”Ÿæˆ {len(core_topics)} ä¸ªä¸»é¢˜çš„è¡¥å……çŸ¥è¯†...")
            for i, topic in enumerate(core_topics, 1):
                print(f"  [{i}/{len(core_topics)}] {topic}...")
                knowledge = generate_supplementary_knowledge(llm, topic)
                if knowledge:
                    # ä¿å­˜åˆ°æ–‡ä»¶
                    filename = f"{SOLUTIONS_DIR}/çŸ¥è¯†ç‚¹_{i}_{topic[:10]}.md"
                    with open(filename, 'w', encoding='utf-8') as f:
                        f.write(f"# {topic}\n\n{knowledge}\n")
                    
                    # æ·»åŠ åˆ°å‘é‡åº“
                    solved_docs.append(Document(
                        page_content=f"{topic}\n\n{knowledge}",
                        metadata={'type': 'supplementary_knowledge', 'topic': topic}
                    ))
                    print(f"    âœ… å·²ç”Ÿæˆå¹¶ä¿å­˜")
        
        # æ­¥éª¤ 4: åˆå¹¶æ‰€æœ‰æ–‡æ¡£å¹¶åˆ›å»ºå‘é‡å­˜å‚¨
        print(f"\nğŸ“Š åˆå¹¶æ–‡æ¡£...")
        all_documents = splits + solved_docs
        print(f"âœ… å…± {len(all_documents)} ä¸ªæ–‡æ¡£ç‰‡æ®µ (åŸæ–‡: {len(splits)}, è§£ç­”+çŸ¥è¯†: {len(solved_docs)})")
        
        vectorstore = create_vectorstore(all_documents, CHROMA_DIR)
        
        # æµ‹è¯•æ£€ç´¢
        print("\nğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
        test_query = "ä»€ä¹ˆæ˜¯é©¬å°”å¯å¤«é“¾"
        results = vectorstore.similarity_search(test_query, k=2)
        print(f"æŸ¥è¯¢: '{test_query}'")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç‰‡æ®µ")
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æ­¥éª¤å®Œæˆï¼")
        print("="*60)
        print(f"   ğŸ“ å‘é‡æ•°æ®åº“: {CHROMA_DIR}")
        print(f"   ğŸ“ è§£ç­”æ–‡ä»¶: {SOLUTIONS_DIR}")
        print(f"   ğŸ“Š æ€»æ–‡æ¡£æ•°: {len(all_documents)}")
        print("   ğŸš€ è¿è¡Œ 'python main.py' å¼€å§‹é—®ç­”")
        
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
